{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract video ID from URL.\n",
    "\n",
    "    Args: \n",
    "        url(str): youtube video url\n",
    "\n",
    "    Returns:\n",
    "        Youtube video's video ID\n",
    "    \n",
    "    \"\"\"\n",
    "    if \"=\" in url:\n",
    "        return url.split(\"=\")[-1]\n",
    "\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_text_from_video(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Get transcript text from YouTube video.\n",
    "\n",
    "    Args:\n",
    "        url(str): youtube video url\n",
    "\n",
    "    Returns:\n",
    "        Youtube video's transcripted text\n",
    "    \n",
    "    \"\"\"\n",
    "    video_id = parse_url(url)\n",
    "    \n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "        transcript_text = \" \".join([entry[\"text\"] for entry in transcript])\n",
    "        transcript_text = transcript_text.replace(\"\\n\", \" \").replace(\"'\", \"\")\n",
    "        return transcript_text\n",
    "    except Exception as e:\n",
    "        return f\"Failed to retrieve transcript: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstax = get_text_from_video(\"https://www.youtube.com/watch?v=zmLQ0yBaN3U\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dimon.txt',\"w\") as f:\n",
    "    f.write(dimon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Failed to retrieve transcript: \\nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=zmLQ0yBaN3U! This is most likely caused by:\\n\\nSubtitles are disabled for this video\\n\\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dstax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load text from file\n",
    "with open(\"xgove_team_call.txt\", \"r\") as f:\n",
    "    transcript = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(transcript_text: str) -> list:\n",
    "    \"\"\"\n",
    "    Split transcript text into processable chunks.\n",
    "\n",
    "    Args:\n",
    "        transcript_text (str): Youtube video's transcripted text\n",
    "\n",
    "    Returns:\n",
    "        processable chunks\n",
    "    \n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_text(transcript_text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = create_chunks(dimon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Failed to retrieve transcript: \\nCould not retrieve a transcript for the video https://www.youtube.com/watch?v=2s! This is most likely caused by:\\n\\nSubtitles are disabled for this video\\n\\nIf you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You can start after I share the screen. Alright, Marta, you're good to go. Hello, good morning, good afternoon, good evening everyone. Welcome to our enablement session. Thank you so much for taking your precious time to join us today. Today we will be exploring the new key features of WatsonX governance along with the new sales tactics defined along with around of them. So with you today, if we can move to the next slide. My name is Marta Świątkiewicz-Tańska. I am Worldwide WatsonX governance sales leader and I'm thrilled to be joined by our worldwide cross function team. And we have a yet field that we are joined also by our guest speaker, Mohamed, who will share with us a fabulous one IBM win story. Before we start, let's go through very quick rundown. What is on our agenda for today? So we will start with quick recap. What is available available today in terms of software, SaaS, WatsonX governance deployment option. Then we will go into our product enhancements. And as you can\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(chunks: list) -> str:\n",
    "    \"\"\"\n",
    "    Summarize text chunks and create a single summary.\n",
    "    \n",
    "    Args:\n",
    "        chunks (list): processable chunks of transcriptted text\n",
    "\n",
    "    Returns:\n",
    "        A single summary for youtube video\n",
    "    \"\"\"\n",
    "    llm = OllamaLLM(model=\"llama3\")\n",
    "\n",
    "    template = \"\"\"Text: {text}\n",
    "    Goal: Summarize given text.\n",
    "    Answer: \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | llm\n",
    "\n",
    "    summaries = [chain.invoke({\"text\": chunk}) for chunk in chunks]\n",
    "    \n",
    "    combined_summary = \" \".join(summaries)\n",
    "    \n",
    "    # Create final summary\n",
    "    final_summary_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Multiple summaries: {summaries}\\nGoal: Create a coherent single summary.\\nAnswer: \"\n",
    "    )\n",
    "    final_summary_chain = final_summary_prompt | llm\n",
    "    final_summary = final_summary_chain.invoke({\"summaries\": combined_summary})\n",
    "    \n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_summ = get_summary(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a concise summary:\\n\\nA 50-year-old individual embarks on a new journey, transitioning from mere survival to thriving. After facing various life challenges, including divorce, single parenthood, and significant life changes, they've realized the importance of living intentionally. To share their experiences and connect with others who may be facing similar struggles, they're starting a vlog that documents their self-discovery, adventure, and growth. The speaker aims to inspire others by showcasing everyday moments, sharing lessons learned from parenting, and exploring healthy living practices. By doing so, they hope to demonstrate that even small moments can hold beauty and significance, and that it's never too late to start making positive changes in life.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"xgov_summ.txt\", \"w\") as f:\n",
    "    f.write(ds_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topics(chunks:list) -> list:\n",
    "    \"\"\"\n",
    "    Extract main topics from text chunks.\n",
    "    \n",
    "    Args:\n",
    "        chunks (list): processable chunks of transcriptted text\n",
    "    \n",
    "    Returns:\n",
    "        Main topic list\n",
    "    \"\"\"\n",
    "    llm = OllamaLLM(model=\"llama3\")\n",
    "\n",
    "    template = \"\"\"Text: {text}\n",
    "    Goal: Extract main topics from the given text.\n",
    "    Answer: List the key topics separated by commas.\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | llm\n",
    "\n",
    "    topics_list = [chain.invoke({\"text\": chunk}) for chunk in chunks]\n",
    "\n",
    "    # Combine topics from different chunks\n",
    "    all_topics = set()\n",
    "    for topics in topics_list:\n",
    "        # Split comma-separated topics and clean whitespace\n",
    "        topic_items = [t.strip() for t in topics.split(\",\")]\n",
    "        all_topics.update(topic_items)\n",
    "\n",
    "    # Remove empty elements\n",
    "    all_topics = {topic for topic in all_topics if topic}\n",
    "    \n",
    "    return list(all_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops = extract_topics(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tops)\n",
    "with open(\"xgov_topics.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(tops))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quotes(chunks:list) -> list:\n",
    "    \"\"\"\n",
    "    Extract important quotes from text chunks.\n",
    "    \n",
    "    Args:\n",
    "        chunks (list): processable chunks of transcriptted text\n",
    "    \n",
    "    Returns:\n",
    "        important quotes list\n",
    "    \"\"\"\n",
    "    llm = OllamaLLM(model=\"llama3\")\n",
    "    template = \"\"\"Text: {text}\n",
    "    Goal: Extract the most important quote from this text.\n",
    "    Answer: Provide the quote as plain text.\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | llm\n",
    "\n",
    "    quotes = [chain.invoke({\"text\": chunk}) for chunk in chunks]\n",
    "    \n",
    "    # Filter duplicate or empty quotes\n",
    "    unique_quotes = []\n",
    "    seen_quotes = set()\n",
    "    \n",
    "    for quote in quotes:\n",
    "        # Normalize quote (clean whitespace and compare lowercase)\n",
    "        normalized = quote.strip().lower()\n",
    "        if normalized and normalized not in seen_quotes:\n",
    "            unique_quotes.append(quote.strip())\n",
    "            seen_quotes.add(normalized)\n",
    "    \n",
    "    return unique_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = extract_quotes(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"xgov_quotes.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Welcome to our enablement session. Thank you so much for taking your precious time to join us today.\"',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"We have very interesting agenda for today.\"\\n\\nThis quote stands out as it sets the tone for the meeting and hints at the exciting topics that will be covered.',\n",
       " '\"What we can see on this slide, this is our IBM Business Value Institute point of view where we are shifting from experimenting to scaling and optimization of governance and innovating all the related use cases.\"',\n",
       " 'Here is the most important quote:\\n\\n\"end to end governance program platform, which is consolidated around risk and compliance and model management capabilities.\"',\n",
       " '\"We expect in second half of this year, the WatsonX governance standard plan, which is combining risk console and model management capabilities.\"',\n",
       " '\"One of the core elements that our clients are looking to drive towards is the idea of being able to manage and understand their compliance posture. Where do they sit within the growing regulation footprint across the world?\"',\n",
       " 'Here is the most important quote from the text:\\n\\n\"We\\'d look to maybe onboard the different types of foundation models. Is it Grok? Is it Granite? It\\'s a DeepSeek R1, whatever you\\'ve chosen as being your organization\\'s element...\"',\n",
       " '\"What do I need to do to be compliant as a use case owner, data scientist, etc.\"',\n",
       " '\"So again, a very large footprint of regulation growing.\"',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"They need to go ahead and actually assess the compliance based on the evidence provided by our use case owner.\"\\n\\nPlain text: \"They need to go ahead and actually assess the compliance based on the evidence provided by our use case owner.\"',\n",
       " '\"Our primary job is to record the evidence for each obligation.\"',\n",
       " 'Here is the extracted quote:\\n\\n\"Gross of regulations compliance owners need to go ahead and be able to evaluate. They need to be able to look at those across multiple different frameworks, including the EU AI Act and external frameworks like NIST AI RMF or ISO standards.\"',\n",
       " '\"What it is, just to be clear, it\\'s data as a service.\"',\n",
       " '\"So what it is, just to be clear, it\\'s data as a service.\"',\n",
       " '\"We have a library of compliance plans and then distributed compliance plans. The additional ones are those that are being assessed at the use case level.\"',\n",
       " '\"So for example, here I can see for New York City 144. We actually have 5% of our obligations have been met and only 5% have been assessed.\"',\n",
       " '\"So you\\'d be able to link through to those metrics that you\\'re evaluating as part of the rest of what\\'s next governance.\"',\n",
       " '\"So all the different elements of risk information, use case details, but you\\'ll now see some different elements under here.\"',\n",
       " 'Here is the most important quote:\\n\\n\"You see a compliance evaluation... Rahul has 70 different things he has to do. 70 obligations he needs to confirm.\"\\n\\n Plain text: \"You see a compliance evaluation... Rahul has 70 different things he has to do. 70 obligations he needs to confirm.\"',\n",
       " '\"So if there was a cross-over between these 20 and 50, it would be far more harmonized.\"',\n",
       " 'Here is the most important quote from the text:\\n\\n\"I can see where we are, where they are in a given cycle, who\\'s assessed what, and if they\\'ve been assigned to different states.\"\\n\\nLet me know if you need anything else!',\n",
       " '\"I\\'ll get to those shortly.\"\\n\\n(This is the most concise and straightforward quote in the text.)',\n",
       " '\"I think what\\'s really important from our point of view is we start thinking about it. It actually reinforces IBM\\'s posture around the fact that we are model agnostic.\"',\n",
       " '\"I don\\'t want my data heading back to China.\"',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"Enterprises with an AI governance platform integrated in their IT environment are able to rapidly test and assess new large language models prior to deployment potentially gaining advantages in speed and agility.\"',\n",
       " 'Here\\'s the extracted quote:\\n\\n\"bringing together complete capabilities we have across what\\'s next governance really allows our organizations, our customers to be able to go ahead and take advantage of some of the other non risk based benefits that you might get from using something like deep seek\"',\n",
       " '\"What\\'s next governance light and essentials plans are available in North America and Dallas on the IBM cloud and it\\'s been there since 2023.\"',\n",
       " 'Here is the extracted quote:\\n\\n\"We are planning Singapore for March, April, probably closer to an April timeframe to release that\"',\n",
       " '\"So if a customer actually in SageMaker takes an LLM and they registered in the registry, That integration is support us will be able to import those those models as well as the predictive models.\"',\n",
       " '\"One step. One manual stuff that is never avoided.\"',\n",
       " '\"One of the One of the most popular questions that we get from the field is what\\'s happening with governance of a Vagentic AI.\"',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"Some of the challenges, some of the risks, some of the security concerns are just absolutely amplified.\"\\n\\nThis quote highlights the increased complexity and risk associated with autonomous agents in AI.',\n",
       " '\"We want to harden it and deliver the capabilities out of the box.\"\\n\\n(Note: This is a straightforward extraction, as there is no specific quote with quotation marks in the provided text.)',\n",
       " '\"We are absolutely having those ongoing conversations with AI and orchestrate to maintain alignment.\"',\n",
       " 'Here\\'s the most important quote extracted from the text:\\n\\n\"When I say how many experiments are run, it\\'s basically every time that a user clicks on that run experiment.\"\\n\\nPlain text:',\n",
       " '\"So if you look at 10 experiments per month times 15 is about 150 resource units at 60 cents a resource unit. That\\'s $90 per month or $90 per month.\"',\n",
       " '\"reach out to product management if you need help in some sizing or figuring out what to do with the guardrails.\"',\n",
       " '\"We want to act upon and really we want to approach our enterprise clients and position Watson X-Governance with IBMC.\"\\n\\n(Note: This is the most important/extracted quote from the original text)',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"We understand AI will fail without governance.\"\\n\\nLet me know if you need anything else!',\n",
       " '\"So let\\'s move to the next slide.\"\\n\\n(Note: This quote seems to be a transition statement, passing the floor to Michael)',\n",
       " '\"So sometimes for customers that maybe would deploy this on their own hardware, hardware can be difficult to find in these environments, especially GPUs.\"\\n\\n(Note: This is a direct quote from the text, extracted as plain text.)',\n",
       " '\"Fusion can be a great option across all the AI offerings.\"',\n",
       " '\"So the idea here is to make this configuration super easy to do and also really facilitate interaction between the Fusion teams and the Watson X teams as well, working through common tooling in order to address the customer use cases and the customer requirements as well.\"',\n",
       " '\"So the teams will still focus on the areas that they have focused on in the past. But the idea is the teams work together and it\\'s sort of a better together story with tooling, in this case the configurator tooling, supporting both sides.\"',\n",
       " 'Here\\'s the extracted quote in plain text:\\n\\n\"When these things are put together and hardware is included, these deals can be quite large and certainly can be advantageous both for us and for the customer as well...\"',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"We actually were quite successful over the last three quarters.\"\\n\\nLet me know if you\\'d like me to help with anything else!',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"So that\\'s the difference there. Prod and non-prod are supported.\"',\n",
       " '\"So those are some of the programs that are available.\"\\n\\n- Michael',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"This is a story of strategic partnership, tough competition as always, and how we made WatsonX.gov the clear choice for a major telco player in the region.\"',\n",
       " 'Here\\'s the most important quote extracted from the text:\\n\\n\"This is one of the largest models generating companies I came across.\"',\n",
       " '\"We had a lot of workshops in alignment. We\\'ve done multiple hands-on sessions with the AI team about what ethical AI is and the ethical department.\"',\n",
       " '\"So when we started brushing down the licensing model in the beginning, it was very difficult. Thanks to the product team, we managed to work out a very, very simplified model with a single, easy to understand metric that made a huge difference when it came to the TCR calculations.\"\\n\\n(Note: This quote seems to be highlighting the challenges and successes of implementing IBM\\'s governance platform for AI models.)',\n",
       " 'Here\\'s the extracted quote:\\n\\n\"AI governance is a huge opportunity.\"',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"We\\'re gearing crazy amount of requests after the announcement to understand how we\\'ve done it.\"',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"AI is a team sport.\"\\n\\nThis quote highlights the collaborative nature of AI efforts, emphasizing that it requires coordination and teamwork across different teams to achieve success.',\n",
       " 'Here is the extracted quote:\\n\\n\"Attach services to your software deals.\"',\n",
       " '\"Sellers can easily retire their service sales quota faster by leveraging services in their software deals.\"',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"We create a solution topology and implementation plan that will help allow the customer to establish monitoring and explainable AI in tests and in production.\"\\n\\nThis quote highlights the key goal of the advise services, which is to help customers plan and implement an effective AI governance solution.',\n",
       " '\"Our day two expertise connect operation service provides customers with a SME who can proactively guide the customer in their use of the technology.\"',\n",
       " '\"If you have any questions you can ask on the hashtag #ask expert labs Slack channel as well as on our seismic pages, be happy to help and assist with any services questions you may have.\"',\n",
       " 'Here is the most important quote from the text:\\n\\n\"Regardless from a data and AI perspective or consulting, we are also sponsoring booths at the IAPP conferences...\"\\n\\nLet me know if you\\'d like me to help with anything else!',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"Do reach out to our team.\"',\n",
       " '\"We would love to hear about it. So or if you see something that like a competitor is doing to say, hey this is what good AI governance marketing looks like, feel free to share that with us.\"',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"There\\'s actually a webinar tomorrow on governing and securing AI with us and the Guardian team if you or your clients would like to attend.\"',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"And then chapter four again continuing to scale agentic AI building those capabilities in terms of both evaluation metrics and other ways of governing agents.\"',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"Please remember that [it\\'s really very precious information]\"\\n\\nLet me know if you\\'d like me to clarify or provide further assistance!',\n",
       " 'Here is the most important quote extracted from the text:\\n\\n\"Thank you so much for today and happy selling.\"']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ytubetrans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
