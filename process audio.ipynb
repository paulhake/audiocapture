{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.4)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/7.1_4 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.100 / 61. 19.100\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'avient2024.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isommp41mp42\n",
      "    creation_time   : 2025-02-14T01:43:49.000000Z\n",
      "  Duration: 00:48:15.30, start: 0.000000, bitrate: 60 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 160x90 [SAR 1:1 DAR 16:9], 4 kb/s, 10 fps, 10 tbr, 600 tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-02-14T01:43:49.000000Z\n",
      "        handler_name    : Core Media Video\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 54 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-02-14T01:43:49.000000Z\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'avient2024.wav':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isommp41mp42\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-02-14T01:43:49.000000Z\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 pcm_s16le\n",
      "[out#0/wav @ 0x7fb6b6221800] video:0KiB audio:90479KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000084%\n",
      "size=   90479KiB time=00:48:15.31 bitrate= 256.0kbits/s speed=1.05e+03x    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffmpeg', '-i', 'avient2024.mp4', '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', 'avient2024.wav'], returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "input_file = \"avient2024.mp4\"\n",
    "output_file = \"avient2024.wav\"\n",
    "\n",
    "subprocess.run([\"ffmpeg\", \"-i\", input_file, \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", output_file])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"medium\")\n",
    "print(\"Whisper loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulhake/opt/anaconda3/envs/audiocap/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You can start after I share the screen. Alright, Marta, you're good to go. Hello, good morning, good afternoon, good evening everyone. Welcome to our enablement session. Thank you so much for taking your precious time to join us today. Today we will be exploring the new key features of WatsonX governance along with the new sales tactics defined along with around of them. So with you today, if we can move to the next slide. My name is Marta Świątkiewicz-Tańska. I am Worldwide WatsonX governance sales leader and I'm thrilled to be joined by our worldwide cross function team. And we have a yet field that we are joined also by our guest speaker, Mohamed, who will share with us a fabulous one IBM win story. Before we start, let's go through very quick rundown. What is on our agenda for today? So we will start with quick recap. What is available available today in terms of software, SaaS, WatsonX governance deployment option. Then we will go into our product enhancements. And as you can see, we have very interesting agenda for today. We will go through the regulatory compliance accelerators, WatsonX governance positioning for DeepSeq, new features for AWS SageMaker and our point of view on agentic governance. Finally, we will share some update how to size Cartials and Evaluation Studio, which were launched last quarter. Then we will move through sales GPM updates where we will see what are the tactics which we plan for first half of this year. And then as mentioned already, we will hear from Mohamed a great win story from our client from last quarter. So very excited about that. And then we will see some updates how to engage with, for example, expert labs and how the sellers can be compensated. And what is our possibility to really position WatsonX governance with client zero story. And then we will conclude with marketing update and call to action. So moving forward, let me of course share the previous slide, maybe for a second, as we will be sharing some forward looking statements related to the product. So please consider this content as confidential and open for IBM audience and also business partners. With that, let's move to the next slide. Last year, I want to thank you all of you to all the contribution in business development around WatsonX governance and executing all our opportunities, which concluded in fabulous wins across the globe. So last year, we could see that there was a lot of experiment, experimenting around governance this year. What we can see on this slide, this is our IBM Business Value Institute point of view where we can see we are shifting from experimenting to scaling and optimization of governance and innovating all the related use cases. Let's move to the next slide. So let's do a quick recap. What is available in the market space and how we can position WatsonX governance, both for software and sales. From a software perspective, we have the new release back to December when we launched 2.1. And this is the end to end governance program platform, which is consolidated around risk and compliance and model management capabilities. This software is available also as a bring your own license subscription model and of course available in IWS and Azure commercial marketplace. From SaaS perspective, we have WatsonX governance available for model management on IBM Cloud and also as a risk console on AWS. Let's move to the next slide. And here is some visual representation how our SaaS deployment plan is today available for our clients and what we expect in terms of upcoming manners. So today, as you can see, we have model management capabilities on IBM Cloud in Dallas, in Frankfurt and the recent launch was in Sydney. And we expect in Toronto in Q1 to expand IBM Cloud model management capabilities as well. As you can see, we expect in second half of this year, the WatsonX governance standard plan, which is combining risk console and model management capabilities. Now moving to AWS. As you can see, we are deploying WatsonX governance for risk console. We put this on data center with AWS in Northern Virginia and also in Frankfurt. And then we expect in Q2 the data center available in Singapore. As you can see also, there is upcoming enhancement for our WatsonX governance integrated with AWS SageMaker where we will integrate governance console with AI fact sheets and evaluation and monitoring. Let's move to the next slide. Okay, so I have given some spoilers already. Now I'm transitioning to Ian, where we will start presenting all the upcoming enhancements in WatsonX governance. Fantastic. And thank you very much, Marta. I just want to confirm folks can see my screen, hopefully. Great. All right. So really what we're going to be talking today, we've done a lot of work over the past few years with IBM WatsonX governance where we've done the idea of the evaluation and monitoring. We've had the idea of risk assessment, use case onboarding, our EU AI Act, risk ratings, etc. But one of the core elements that our clients are looking to drive towards is the idea of being able to manage and understand their compliance posture. Where do they sit within the growing regulation footprint across the world? So what we've been doing is really looking to enhance those capabilities. So today I'm going to give you a bit of a sneak peek around some items we've got as well as a brief demonstration as well. Okay, so if we look at this, if we start with just at the highest level, we start a typical onboarding of an AI use case and cycle. We look at a business problem. We'd identify that we document that use case and capture the relevant information around that use case. Again, we'd look to maybe onboard the different types of foundation models. Is it Grok? Is it Granite? It's a DeepSeek R1, whatever you've chosen as being your organization's element because they sort of, to some degree, those are an onboarding process is distinct away from the idea of the individual use case. So we then take that onboard a little bit further. We'd say actually when we start applying those two things together, we go through a use case approval process. Now, that use case approval process could be multiple different stakeholders, you know, technology, legal, procurement, etc. All being engaged here. In this case, one of the core areas we're looking at in the governance console in particular is three different capabilities. One we've already captured historically around the idea of risk identification and risk assessment, the idea of which regulations are applicable, but also the idea of understanding how do I know that I'm compliant? What do I need to do to be compliant as a use case owner, data scientist, etc. And again, from there, we move off into a different process, whether you're purchasing AI tooling, go through building prompts, etc. Fine tuning, building a rag, etc. Again, historically, these processes will be organizationally specific, but I guess one of the things we're going to do now is really take a look at what we're doing around the compliance assessment process. So what do I mean by that compliance assessment process? Well, to a degree, if we start with the idea there is a suite, an element of a vast footprint that organizations have to apply, either internal frameworks, external frameworks such as NIST. Are all they getting regulations such as EU AI Act or New York City 144 or again, the growing footprint. And just as a view, there are regulations popping up all over the place, even though there's been different posture changes in US regulations, you're starting to see more state regulations roll in. So again, a very large footprint of regulation growing. So you take that organization would take that information and then build up their library, the things that they need to do with library maintenance process. They go through and again, try to go with the descriptions around those different elements. We take that information, align that to the use case, distribute that out to the use case owner and then ask the use case owner to provide the appropriate evidence around whether it's an attestation, whether it's a attaching to a metric, documentation, file attachments, screenshots, a number of different elements to go ahead and prove that they've actually complied with a certain piece of regulation or they've got evidence. They then have a conversation with their compliance teams and really move forward with the recording and response and going all forward from there. Now to that degree, we're really trying to satisfy the stakeholders of two types. Our compliance officer who wants to go to view the level of regulations that they need to be applicable with. They need to go ahead and actually assess the compliance based on the evidence provided by our use case owner. And they need to be notified that you've got to respond to things that are not being met and also being able to author and manage those different requirements as they come through. Our other stakeholders, our use case owner. The use case owner's primary job is to go ahead and record the evidence for each obligation. They want to have visibility of where they have any other obligations and then also have visibility of any other particular regulations that might be arising and then recording issues where they're moving through and doing a gap analysis on the way through. So how does that work? So effectively to deliver what we want to see is a piece of AI use case compliance. We're able to say actually we've got our capabilities and again one of the modules within the What's Next governance is our Reg compliance management. So you bring that side of it and the organization needs to bring to that story an idea of some elements around what other regulations that are applicable. What is that level of compliance that you need to offer? Now to that end, you bring those two parts and it's giving the organization the ability to go ahead and assess their own regulatory compliance. So how are we doing that? What we've gone forward with from there. We've already got this piece around RCM, but we've got the idea now introducing effectively an element to cover the data side of this. So What's the next governance compliance accelerator? We have talked through a little bit of this problem that the organization would have in these slides or sort of touched on some of those, but gross of regulations compliance owners need to go ahead and be able to evaluate. They need to be able to look at those across multiple different frameworks, including the EU AI Act and external frameworks like NIST AI RMF or ISO standards. This is coming at the end of this quarter as a subscription part. We've got a few elements we're just tying off with our providers around this, but it can be leveraged by What's Next governance console deployments, both whether it's a self managed, i.e. the client's on premise deployment, or it can be done as part of the SAS. The idea here is what we're talking about is a data as a service part. So again, we'll be making files available that the customer can then import into their library of compliance areas. OK, so these will be brought through and they'll have regular quarterly updates. Some of you may have seen the phrase we've been talking historically about things like Credo policy, Credo AI policy packs. This is taking that content and creating the IBM version, which is our Watson regulatory compliance accelerator. So the content we've taken from Credo and producing for our clients. It's a slightly different structure. We have to rework a little bit, but it comes forward and sits inside of the application. So what it is, just to be clear, it's data as a service. It's libraries of regulatory content and obligations. What it isn't is we're not licensing Credo software. We're licensing content from Credo as part of this process of making it available to that degree. OK, just so you're very aware, GA targeting end of March, demo assets end of March from the tech sales teams, etc. Sales materials recorded be coming over in the next few weeks around this. Now I just wanted to, if I can, spend a couple of minutes really conscious of time to give you a brief demonstration of the content within the solution. I'm sure there might be some questions in the chat. Feel free to log those and I'll answer those as we go forward from here. But let me now just log in and give you a view of what the solution looks like. So here I've logged in as Lana, who's my compliance officer. She has a slightly different homepage for herself. You'll see she has a portal here around her compliance plans. The compliance plans, think of those as being a library of compliance plans and then distributed compliance plans. The additional ones are those that are being assessed at the use case level. So again, I could have my different footprints of each of those. I'm just going to go into one or two of them briefly, but we have a library of those. And again, there's a much broader suite and we will provide details of all of the regulations and frameworks being covered as we go through the release process. But if we start to go into that a little bit further, we can maybe start looking at some of these. So I can go to my library compliance plans here. I'll have a list. You'll see here in this case here the provider is Credo AI. We have other providers out in the ecosystem that's starting to look in this space. So keep an eye out. You'll also, this also means that our customers can also bring in their own content. They don't want to use the content we're getting from Credo under our Watson content accelerator here. They can also bring it in, whether it's KPMG, Deloitte, EY, etc. All have a view around this. You'll see from this point of view within the library, I can also have a central point of view of where I am. So for example, here I can see for New York City 144. We actually have 5% of our obligations have been met and only 5% have been assessed. So I could drill into that information. I can take a look at that data. And here we're going to see some of the information that's made available. So again, where it sits in the library, where it's being distributed, who owns the information, information around applicability. Again, this is content provided as part of the data service that we have available. And then you'll start seeing all the individual obligations that the organization has been set up as far as the compliance activities. So you'll see certain elements. Some have been existing, such as providing text information. Some are yes or no. Others can be information such as metrics as well on the way through. So you'd be able to link through to those metrics that you're evaluating as part of the rest of what's next governance. So if you're doing a bias, in this case here, it's an employment decisioning tool. If you're going to have been using fairness and bias evaluations, you can go ahead and actually link to those to provide the specific information in this case that are being asked for. And again, some of them are going to be tables and other pieces of data you might want to look at. But from a compliance point of view, I'm going to have that view. And I can also see all the individual evaluations that are being made by the individual lines of business, etc. So in this case here, I can see that we've had Rahul Onason provide description of that auto employment decision tool. And you'll see it's been marked as complete and being marked as met. Again, limited data set here in this demonstration to give you that footprint. So from a central point of view, this is Lyla's point of view. So she can see exactly what's going on across the different areas. Now, if we wanted to maybe go a little bit further with that and say, actually, what does it look like as far as the use case owner? So Rahul, who's my use case owner. You're going to start seeing some information here where I got all the original screens I'd looked to see. So all the different elements of risk information, use case details, but you'll now see some different elements under here. So you see a compliance evaluation. In this case here, Rahul has 70 different things he has to do. 70 obligations he needs to confirm. Some of them are for New York City 144. And also another suite here are also for the EU AI and the EU high risk system providers. So again, limited data set here in this demonstration to give you that footprint. So from a central point of view, this is Lyla's point of view. So she can see exactly what's going on across the different areas. So you'll see it's been marked as complete and being marked as met. So from a central point of view, this is Lyla's point of view. So again, limited data set here in this demonstration to give you that footprint. So you'll see it's been marked as complete and being marked as met. So you see a compliance evaluation. In this case here, Rahul has 70 different things he has to do. 70 obligations he needs to confirm. Some of them are for New York City 144. And also another suite here are also for the EU AI high risk system providers. So again, bring that point of view. Longer term and obviously following an IBM and Michelle touch on the elements of what we do as client zero, IBM has a point of view for our internal system where we actually generate a standardized baseline just so it's one set of compliance. So if there was a cross-over between these 20 and 50, it would be far more harmonized. We're not there yet and the data provider isn't there yet either. But that's something we're targeting for moving with customers as we go forward. But just giving you that point of view around the way through, I can see where we are, where they are in a given cycle, who's assessed what, and if they've been assigned to different states. So that's something we're targeting for moving with customers as we go forward. But just giving you that point of view around the way through, I can see where we are, where they are in a given cycle, who's assessed what, and if they've been assigned to different states. So that's something we're targeting for moving with customers as we go forward. But just giving you that point of view around the way through, I can see where we are, where they are in a given cycle, who's assessed what, and if they've been assigned to different states. So that's something we're targeting for moving with customers as we go forward. Finally, if you want to have a quick look at it as well, we also have the ability to be able to go into a mandate from a rate from a legal point of view and run off compliance reports that give us that point of view. So if I need to see exactly where I am across any given regulation, I can go ahead and run off the mandate compliance report and work out what's being covered. What are the individual use cases that are applicable and also start looking at the data and how it all hangs together where it's broken down. So again, doing some more work around this, but just wanted people to be aware of those on the way through. So again, super high level, but just trying to give you folks a flavor. This will do more detailed enablement, put recordings etc. out over the coming weeks as well. Now before I round out, I know I'm running close to time. I was also, I've seen some questions in the chat. I will get to those shortly. Just the last little bits I want to cover off was also around the elements of what we're talking about from a deep seek point of view. Again, this is more point of view, just interesting people can understand if you help clients asking you about deep seek and what's going on. These are things that you should be able to point towards. Obviously it was a key topic across the industry over the past few months. And it's been particularly exciting. You'll see some some great headlines around this year. The Italian regulators blocking it. Australia banning deep seek over risk. Now again, there are different elements. So in this case here, this is governance being deployed governance in action to some degree. Looking at people saying what do we need to look at from this point of view. But I think what's really important from our point of view is we start thinking about it. It actually reinforces. You've probably seen some of these materials. This reinforces IBM's posture around the fact that we are model agnostic. We can work with your locally deployed models if we need to. We can still go ahead and actually promote the use of open source models. So again, just trying to touch on those. There are different elements to think about. If you're talking to a client, they're saying I don't my data heading back to China. Well, the idea of being able to use our IBM Watson tooling and running a local instance that model will stop some of that from happening. So there are ways we can start to look at those different elements. So again, just trying to again will make these materials available, but do keep an eye on size. There's some very important information around that. The one that I do want to touch on really briefly. This is actually by from an external organization holistic AI. Whoever governs tooling of sorts, but they actually did some some audit analysis work around the use of around deep seek in particular. And again, the statistics around are very interesting. Very close. They compared it with open AI 01 model. Yeah, you'll see the safe responses were pretty close unsafe responses when testing were were a little bit flawed. But the NC jailbreaking in particular. So open AI was giving them 100% safe responses when you're asking it to do something it shouldn't do and the deep seek R1 was actually was was actually going through and only giving 32% safe responses. So again, bit of a concern. But I think the important part when you read the paper around this and I do want people to take a look at this. But enterprises with an AI governance platform integrated in their IT environment are able to rapidly test and assess new large language models prior to deployment potentially gaining advantages in speed and agility. Additionally, they're able to enforce guardrails and the use of the LL ends across the organization. So really interesting in that sense. It's pulling out some of our core capabilities that we actually have within what's next governance. The idea of being able to The idea of being able to to rapidly go ahead, test, evaluate, carry out risk assessments, all those things we need to do. And then as well as that the end of last quarter, you saw the idea of introductions of guardrails being made available. So again, bringing together complete capabilities we have across what's next governance really allows our organizations, our customers to be able to go ahead and take advantage of some of the other non risk based benefits that you might get from using something like deep seek as an example. So I'm going to answer the questions in the chat on some of the accelerator piece, but please feel free to reach out to me directly. I'm now going to hand it across or hand it back to the team and I think Neil's up next to do some presentation as well. Thank you Ian. Next slide. You build it out. One more quick. There you go. Hey everyone. So this is for those of you that participated in the what you need to know North America call last night. This is going to be this is a bit of a deja vu. This is a much the same content that we covered yesterday. So we covered a lot of this in the Q4 enablement but felt it was worthwhile. Recapping and touching on touching on it again and highlighting any differences. So from a SAS perspective, currently the what's next governance light and essentials plans are available in North America and Dallas on the IBM cloud and it's been there since 2023. We also released in Europe in Frankfurt in Q4 2024. We released in Australia in Sydney in Q4 2024 and we're just about to release in Toronto. This week or next. So those that's where what's next the governance the lightning essentials, which is basically the model monitoring pieces right the the fact sheet as well as the the open scale component. We are also or what's the next governance the standard, which is basically the the model risk governance the governance console is available on AWS and AWS marketplace. In North America, Northern Virginia. That was something that we released mid 2024 we did release in Frankfurt in Q4. So that's a recap. We are planning Singapore for March, April, probably closer to an April timeframe to release that we are also it's duplicate here, but we are also looking at adding the model management capabilities on AWS and as part of that that plan in In the standard plan. We're currently targeting Q2 2025. So the second line is correct. The first line, not so much. Wanted to talk about the just some updates that we also made to SageMaker as most of you probably recall. You know, we released an initial Integration between what's the next governance and and SageMaker sorry and what's the next governance governance console energy and SageMaker back in mid 2024 With in the mid 2020s. So we're looking at the Back in mid 2024 With in Q4 we actually released some updates where we now support an integration between.gov and Model registry direct you may recall that it was previously with the model cards and now we no longer required customers to to generate a model card in SageMaker But this also enables is, you know, we get all we often receive questions around support for Gen. AI and not just necessarily predictive So if a customer actually in SageMaker takes an LLM and they registered in the registry. That integration is support us will be able to import those those models as well as the predictive models. The other thing that we did. Is previously, you know, customers would create an AI use case in Watson next on governance. Once it went through approval and in the models got built inside SageMaker It required some manual steps to go and link the model from SageMaker. Once it was back in in in.gov to the AI use case that was approved. Now we do that automatically. So once the AI use case is approved, we generate a model car a model group. Excuse me in SageMaker when the model gets created underneath and associated to that that model group that is automatically associated back to the AI use case. So one step. One manual stuff that is never avoided. And then the last piece that we wanted to that I want to highlight on the Enhancements to the integration was that previously we supported one instance of.gov to a single instance of our single account of SageMaker. Now with a single instance of governance, we can actually connect and integrate with multiple SageMaker accounts so that so customers that will have like a dev And a test maybe QA production environment. All of those models are then brought into a single instance of governance and I think we could support actually up to the 10 SageMaker accounts or instances. So that's giving you giving customers that unified view. Next slide. One more time. There we go. One of the One of the most popular questions that we get from the field is what's happening with governance of a Vagentic AI. And there's it's fast and furious. So when we talk about agents, you know, there's We can we can actually look at it as being very similar to a lot of the concepts that we've already been talking about for the past year. So when we, you know, So one of the things that we need to do is we're looking at governing across the lifecycle. Right. We need to manage risk. We need to do some level evaluation monitoring real time detection. Even some of the the metrics that we currently have are very, very similar. We need to, you know, was just talking about regulations, right, and we need to ensure that organizations are complying with with regulations. Some of the one of the key differences, though, is that now, given the autonomous nature of agents, some of the challenges, some of the risks, some of the security concerns are just absolutely amplified. So there's certain things that we could do today and we're, you know, next week we're down at Gartner and there was a demo that was recorded around some of the lifecycle. So we can still build a use case, we can still identify risks, we can still do some level of compliance assessment. You know, we're still talking about an LLM. We're still talking about a prompt, right, there's still some level of customer specific configuration like extending the risk library and the questionnaire and then tracking, you know, various customer policies on agentic AI. That's on my screen. So there's there's things that could be done with some level of configuration out of the box today. We are looking at hardening it and then some of the things that we're working on and sort of targeting the first half, we want to obviously make a big splash at Think, but, you know, being able to create or have that tool and agent catalog and as part of that catalog, being able to capture, you know, some of the metadata about the various agents. And, you know, it's again that central inventory where users can see what agents exist to be able to leverage them, be able to promote them, so on and so forth. We are looking at also having a workflow, right, an out of the box workflow. So you're going to see in the coming weeks, you'll see a demo of something that is that we built just with some simple configuration. But again, we want to harden it and deliver the capabilities out of the box. Identification of risks, any risks specific to agents. I think thus far we're not well actually that's not true. But thus far we are seeing a couple of agent specific risks. But from a compliance perspective, we're not seeing anything. But, you know, again, on an AI use case, the compliance and regulation assessment is still absolutely applicable. There's things that we're looking at around doing tool and agent evaluators, evaluations, experiment tracking in order to be able to select the most appropriate agent for the given use case. And then, of course, production monitoring. And just, you know, so everyone's aware this is not happening in isolation. This is not happening in a bike and a vacuum. We are absolutely having those ongoing conversations with.ai and orchestrate to maintain alignment. And just one last area that I wanted to touch upon was in Q4, we did make some updates to the sales configurator. There was two areas or two capabilities that we delivered. One was around the evaluation studio that was delivered in SAS only. And basically from a sizing perspective, what you need to do is just basically ask customers, you know, how many experiments do they expect to run per month? And you may recall that evaluation studio basically allows you to, allows you to, you know, select a couple of different assets, select the metrics that you want to evaluate and click that run experiment button. And then it'll come back and it'll demonstrate or highlight what asset is best suited for the job for the use case. So when I say how many experiments are run, it's basically every time that a user clicks on that run experiment. Now they can do some slicing and dicing and different analysis once they hit the run experiment. But essentially it is 15 are used. So 10, you know, 15 are used per experiment. So if you look at 10 experiments per month times 15 is about 150 resource units at 60 cents a resource unit. That's $90 per month or $90 per month. The other capability that was updated in the sales configurator was around the guardrails. You may recall that we released guardrails in software only in Q4. There's no new part for that, right? We included it as part of the model management so that it can be used in the same way that we did in Q4. The other capability that was updated in the sales configurator was around the guardrails. You may recall that we released guardrails in software only in Q4. There's no new part for that, right? We included it as part of the model management so that existing customers can gain access to those capabilities. We are continuing to work on providing more accurate sizing guidance. I will say for now, I see Apostle is on the call, that you'll be able to reach out to product management if you need help in some sizing or figuring out what to do with the guardrails. So quickly, I think those are the areas we want to touch upon from a product perspective. And with that, I think I'll turn it over to Marta. Thank you so much, Ian and Neil. So let's go very quickly, but let's see what are our tactics and what are the sales place for Watson X-Governance. So as we could see, also with new enhancements and all the position of our unique value proposition for Watson X-Governance is giving us the chance that we can cover with Watson X-Governance end to end, starting with risk and compliance and model management. So this is how we defined also our sales tactics for first half of this year, where we approach our clients from that perspective that we open the discussion around risk and compliance. And of course, the audience ideally is our enterprise risk and compliance office who are working closely with. And for that tactic, we are about to launch a global worldwide campaign, sales campaign together with IBM consulting that will be launched very soon. We are preparing all the assets for us to prospect together. So the sales accelerator for us, given the fact we have this great enhancement around the regulatory compliance accelerators and the UI Act, we want to act upon and really we want to approach our enterprise clients and position Watson X-Governance with IBMC. The next campaign is more geospecific, where we would like to position risk assessment and use case inventory and approach our select accounts, especially in EMEA. But of course, happy to expand this sales motion to other geos and work together on, for example, preparing some client list which we want to work together with. And then the next tactic is around Watson X-Governance for enterprise data and IT and security, where we would like to approach our clients to explore our joint opportunity to deploy Watson X-Governance for modern management. So this is the ongoing sales tactic for us, which we have seen it was it was resonating very well last year. So this is how we can approach our clients. Wherever is any active opportunity for.ai, we should be able to position Watson X-Governance because we understand AI will fail without governance. And then, as you can see, there is another geospecific sales tactics considering we have this great expansion of our SaaS portfolio. We want to approach our clients specifically in APAC, having this possibility to deploy Watson X-Governance from, for example, our data center, Sydney. Of course, we will be happy, of course, to work also with other geos with that specific sales motion. With that, let's go to the next slide. So, as you can see, there are some accelerators where you can see we prepared a lot of content, which is ready to prepare for any client meeting. So this is our SageMaker better together story as we want to explore this market opportunity for us, specifically focus on Americas and in EMEA. There is also all content prepared for Watson X-Governance, how to position to the Chief Risk Office. And there is content starting with conversation, some client facing assets. So, of course, there is also some content prepared, how to position pilot workshop with our client engineering team. And there is also the ongoing upgrade play from CloudWatch for data and happy to work on the EU AI Act focused sales motion, as we understand. This is the momentum for us to explore with our clients how we can help adopt the EU AI Act across the globe, not only in the 29 member countries. So let's move to the next slide. I think this is now transitioning to Michael, over to you. Yeah, thanks. Thanks, Marta. I appreciate that. Yeah, so what we're going to talk about here for a bit is Fusion HCI and the fit of Fusion HCI into the overall solution. We touched on this a bit last year, but we want to just make sure that you understand that Fusion is available. There are customers that are interested in deploying Watson into the Fusion environment. Some of the reasons to do that include the ability or the need to process sensitive data where the customer can't run on the cloud. As an example, they may need to have high performance, high throughput application models as a use case. In turn, Fusion can fit there because they're fully in control. And also the fact that sometimes for customers that maybe would deploy this on their own hardware, hardware can be difficult to find in these environments, especially GPUs. And that could be another reason why a customer would be interested here. So for customers that want to do AI, but they want to do it in their own environment, Fusion can be a great option across all the AI offerings. Rupa, we can move forward. And so one of the things that why might this be of even further interest to you is the fact that Fusion is now part of what sellers are compensated on. That's a very important thing. When I say sellers, I mean the data and AI sellers. And that's a new ad for this year. Secondly, you'll see this year Fusion is now in the sales configurator. So from a sizing perspective, when you go size out Watson X, and when you look at the configurator, you'll see a Fusion box there as well. You move from the Watson X sizing into the Fusion sizing and in effect size that Fusion box, the hardware and the Fusion software and so on, based on that Watson X configuration, Watson X.AI data and governance configuration that you've created. So the idea here is to make this configuration super easy to do and also really to facilitate interaction between the Fusion teams and the Watson X teams as well, working through common tooling in order to address the customer use cases and the customer requirements as well. So you see some links to the sales kits website and so on. That's available as well. You also see a link to the configurator. But if you go there, you'll know right away Fusion is front and center alongside of Watson X. We can move forward, Rupa. Okay. And this happens to kind of lay out the process, right? Where the process may start with the teams interacting themselves or the teams interact in the configurator. The configurator first generates Watson X configuration. Then in turn, that's fed into the Fusion side and the Fusion side and the Fusion configurator then is used and that configuration is generated as well. It's important for the teams to work together. This is not a case where we would expect data and AI to go through and size a hardware environment along with the software environment. So the teams will still focus on the areas that they have focused on in the past. But the idea is the teams work together and it's sort of a better together story with tooling, in this case the configurator tooling, supporting both sides. Then the passport advantage ultimately provides the order and contracting to the customer, which should make things easier to go and propose and to contract and ultimately deploy as well. And as part of this whole process, when you look at the enablement, there are various services programs that are included such as the such as the teleservices, which are being discussed here later in this presentation, as well as advanced support. Rupo, we can go on. Okay, and this happens to kind of show a bit of an outline on sort of what's involved with this. This lays out the part structure. If you're using both or deploying Watson X.AI data and governance, you'll see the parts. You'll see the Fusion HCI software parts as well. And then you see the hardware also. And this is sort of a sample deal at the bottom, but you can see that when these things are put together and hardware is included, these deals can be quite large and certainly can be advantageous both for us and for the customer as well, especially in cases where the customer has that need, has that sensitive data need plus a difficulty or at least a desire to be up and running day one to not have to implement the configuration themselves on their own hardware. Rupo, we can move forward. Okay, all right. I want to transition Marta had mentioned this before, but this is one of the ongoing plays that we reviewed last year and will continue to execute on this. We actually were quite successful over the last three quarters. The display has been made available, but customers of Cloud Pak for Data with unused VPCs, customers with some of the governance offerings on Cloud Pak for Data as well. These customers have the option, again, if there are unused VPCs as an example, they can move forward and they can bring that unused workload to WatsonX.ai. They can bring it to WatsonX.Governance as well. And you can kind of see a layout of the flow, the from and the to flow. There's a list of parts, actual parts out in the seismic that will give you the detail, but this works for both perpetual parts. There's something called transition parts. It works for subscription parts as well with add-ons. So transition parts provide a customer access to both the old and the new offering for the contracted dates. Add-on parts will provide access to new components that sit on top of the existing components as well. So that's the difference there. Prod and non-prod are supported. There are metrics that would be transitioning or adding on from and to, and those metrics are discussed in the seismic material that's out there as well. Typically it's one-to-one, but for instance with AI governance, it's actually a series of VPCs across products that the customers can get. And there's also, you can see the mandatory services part that exists here and that's available also. And then finally, we're going to just move to one more chart. We continue, if you move forward, Rupa, we continue to offer reserved use for ELA customers. So for customers that are in catalogs, work with your ELA person to be able to go through and take a look at whether these are transactional, or I'm sorry, perpetual catalogs or subscription license catalogs. And if they're, if the offerings are not being used, there's a potential to be able to bring those offerings over to the IBM cloud environment through the reserved use program here. So those are some of the programs that are available. I'm going to pass it back to the team to continue on. Rupa Thank you so much, Michael. So to be conscious on time, I just want to walk through very quickly the demo assets which we prepared for you to prepare the client briefing. So there are fantastic click-through demos which we aligned with our tactics, for example, like Watson X governance for AWS SageMaker, or even Watson X governance for the EOI Act applicability assessment. These click-through demos do not require any take zone reservation. There are also some live demos which of course are available on the take zone. So everything is for us in terms of how we want to demonstrate and showcase Watson X governance unique value proposition. With that, let's transition to Mohamed. Let's move into the fantastic winning story that we can share from Mia. Thank you. Thank you so much, Marta. Can you hear me okay? Marta Yes, we can hear you very well. Mohamed Okay. Hi, everyone. Thank you for the opportunity to speak about this big win with the E& Group, one of the biggest AI governance deals in EMEA, which we're proud of. And this is a story of strategic partnership, tough competition as always, and how we made WatsonX.gov the clear choice for a major telco player in the region. So the challenge and what we're up against, E& Group is one of the largest telcos in the region with 16 opcos across EMEA. With almost 163 billion subscribers, they reported more than 53 billion in revenue last year, that's on the runs, which is about $15 billion. And they are very serious about AI. They're rolling it out across their entire portfolio with 500 models, which is very unusual. This is one of the largest models generating companies I came across. And they have more than 160 machines deployed per hour. They even set up a dedicated AI entity with a chief AI officer in an entire team to make sure that their AI is technical and effective. But with this, they had many challenges. So sizing and cost estimation were tricky. Even understanding the difference between data and AI governance was also a challenge. And honestly, as someone new to IBM as myself, been a couple of months into the role, I was learning about it too. So I didn't know much about what's in x.gov until I put my hand with the team and the customer. And then there was the competition, of course, we're up against Data Robot and Microsoft. While as you know, AI isn't really new, Data Robot is everywhere in telco and they have a lot of AI models generated through Data Robot. They claim that they are a competition and they have a platform as such. But we understood the governance was very limited. They didn't offer an end-to-end capabilities that we brought on the table as IBM. So how did we win and what was our IBM approach? We did turn things to our favor. And here's how it worked. One is we ensured that we engage our leadership. We built a strong relationship and had the E&C as a sponsor. We had Ian, we had Anna Paula and Saad, our E&C, meet with the CEO, talk about the story of our governance and how we are the leading player in the market, which made a huge difference. We had a lot of workshops in alignment. We've done multiple hands-on sessions with the AI team about what ethical AI is and the ethical department. You will see that our competition keeps using ethical AI, but it's not just about being ethical. There's much more depth to the governance platform that IBM offers. And of course, we had a lot of live demos. The team has done a great job and made a huge impact. We showed them how easy it is to onboard and monitor AI models. We used our governance REST dashboard to connect AI initiatives directly to show the business impact. And we simplify complexity. So when we started brushing down the licensing model in the beginning, it was very difficult. Thanks to the product team, we managed to work out a very, very simplified model with a single, easy to understand metric that made a huge difference when it came to the TCR calculations. And in the end, we had Xsplit Labs for seamless integration installation and to prove that IBM and IBM makes a difference. We had Deloitte, we had consulting, and we had six other partners, surprisingly, that never worked with us. But when they understood that WatsonX.gov is in the game for EM, and everybody was all of a sudden interested to work with us. So the win and what it means to IBM is as a result, one of the biggest deals in MIA. IBM is now the trusted AI partner free and group and it means a lot to the telco and the community given the EM logo locally and globally. We secured a major enterprise ELA agreement. And their AI operation now became much smarter, much faster. And as you can see from the photo, they were equally excited and proud to make this to the point where they decided to launch this and got us in the World Economic Forum with the presence of both senior leaders from EM and IBM. So to close this, why it matters to all of us, what we can take away from this that AI governance is a huge opportunity. EM Group is just one example of how companies need strong, ethical, and scalable AI solutions. And we believe after this engagement, IBM is the best positions to provide them other solutions. And I believe this is just the beginning. So the potential, we're gearing crazy amount of requests after the announcement to understand how we've done it. And just after the announcement, we have more than 62 leads just wanting to know what we have done. So with this, I'd like to say congratulations to the team. Thanks to everybody who helped us make this work. And I can assure you that when you open the conversation with the customer about the capabilities that we have, they will go up to you to know how they can bring on board WatsonX.gov. And we're happy to work with you. Whoever needs guidance, whoever needs more information, the team is more than willing to provide you with all the support if you need to help with the communications with the customer. We're working on having EM as a reference. So once that is readily available to become a public reference, of course we'll announce it to let you know as well. So thank you, Martha. Thank you, everybody. Thank you so much, Mohamed. It was awesome to listen to this win story. So we understood, of course, how you work across the teams. And also we understand AI is a team sport. So it was fantastic to see how we approach different audiences on client side and how we work across our teams to win this client. Congratulations. And now we are moving to our next section in the agenda. So how to engage with clients. And today we just want to share some update on the incentives when working with technology expert labs. And also you will go through the client zero story, how we can prospect together. So with that, over to you, Sarah. Thank you so much, Martha. Hi, everyone. My name is Sarah Memmon and I'm the services offering manager for technology expert labs, data platform services. I'm really excited to be here and talk to you about our expert lab services and how to engage with us. So first off, I want to emphasize that it's absolutely crucial to attach services to your software deals. This year, there is a really huge focus on deployment and attaching services is going to help accelerate us to getting to the deployment stage. Our expert labs teams has vast experience and expertise to deliver to deliver Watson X governance solutions at scale. Working with expert labs gives clients an exceptional experience and ensures a high return on investment. In addition to delighting customers, there are direct benefits for IBM sellers and working with expert labs. First and foremost, most seller roles at IBM get a quota retirement from their services. This is 35 to 50% depending on their role. If there is deployment involved of their incentive plan for selling services. Therefore, sellers can easily retire their services sales quota faster by leveraging services in their software deals. And also there's incentives for partners as well. When they sell our services through parts, you can transact our prescoped offerings and services through parts in the IBM quoting tool or with SKUs in Conga. Next slide, please. So for the Watson X governance portfolio, technology expert lab services help customers in three different phases of product deployment. So we can architect solutions and have technology focused consultancies, provide technical hands on expertise to install, configure and support the customer on their journey to production, as well as run and operate the solution for day two operations. The first section architect and advise services assist the customer in getting started with AI governance. We use these services to help the customer define and plan a technology solution. We have a new solution workshop for trusted AI where we work with the customer to understand their existing AI deployment process and the level of control that they need to achieve. We consider policy and regulatory requirements and create a solution topology and implementation plan that will help allow the customer to establish monitoring and explainable AI in tests and in production. The next category build and deploy solutions follows our planning activities and it's where our SMEs support customers with hands on skills to install and deploy Watson X governance. So this includes all things configuration, integrations, customizations if necessary. We can also help the customer with an initial build or use an existing proof of concept or demo as the foundation to have a production rollout. And lastly, our operate services are there to ensure that the customer has access to ongoing assistance after the initial deployment. Our day two expertise connect operation service provides customers with a SME who can proactively guide the customer in their use of the technology. They work closely in collaboration with the customer team and help assist in preparing for new features or new versions and provide that knowledge transfer to ensure that their governance solution continues to align. Lastly, for customers who have purchased software licenses rather than SaaS, we also have a platform management service for Watson X.gov for our customers who need extra assistance accelerating and scaling AI across other lines of business or growing their in-house governance skills or their resources with new innovations. So our essential management service helps the customer respond to this by providing monitoring and helping them manage the application on their behalf. So we also have more slides attached to this deck that provide more info on essential management as well as our learning portfolio. We have a lot of free courses as well as paid courses that you can also attach to your deal. So these are really great references to refer to. And then if you have any questions you can ask on the hashtag ask expert labs Slack channel as well as on our seismic pages, be happy to help and assist with any services questions you may have. Thank you very much and back to you, Marta. Thank you so much. Over to Michelle. Thank you. Hi everyone. I'm from the Office of Privacy and Responsible Technology. I will go fairly quickly through these slides because I know we're almost out of time. You will recognize this slide. It depicts our integrated governance program we've deployed for our privacy and AI governance compliance within IBM. Telling this story to clients helps elevate the trust in the IBM brand. I have put, if you've not seen it, you'll see on the left a link to our seismic page where you can peruse all of the materials we put together to support you in this space. Next slide please. Now our team has contributed to a lot of the sales in AI governance last year. Regardless from a data and AI perspective or consulting, we are also sponsoring booths at the IAPP conferences and I just wanted to call out the successful event that we participated in last November where we had over 50 leads that materialized and that helped drive already an RFP with GE Healthcare. We are going to continue to support the IAPP conferences in 2025. We are going to Dublin in May, in Boston in September and again in Brussels next November. Please do reach out to our team. You see here my team, Anisha Parker, who is located in the US and John Bowman in the UK, we're here to help support your growth with your clients in the AI governance space. Next slide please. This is just a chart that depicts some stats of productivity with our integrated governance program we've deployed internally and at the bottom you see the progression of that integrated governance program and the look ahead, what's ahead with it and it's all about automation and having a do it for me capability built in with Gen. AI into our solution. You can use this slide when you're talking to clients if you want more information about this. Again, please don't hesitate to reach out to us and I'll pass it over to Jordan for a marketing update. Thank you. Thank you Michelle. Hi everyone, Jordan Bird here, product marketing lead for Watt's Next Governance. I started at IBM in October so still getting to know some of you, looking forward to working with the rest of you that I haven't met yet. So I wanted to briefly walk you through the story arc of how we see the first half of all of the different marketing moments and initiatives for Watt's Next Governance. But before I do that, I want to point out that we're always looking for feedback from you, from your clients, from anything you see about how Watt's Next Governance is showing up in our marketing, the messaging. Is there something that really resonated with your client or doesn't really work? We would love to hear about it. So or if you see something that like a competitor is doing to say, hey this is what good AI governance marketing looks like, feel free to share that with us. So I've linked the form here that'll go directly to myself and my colleague Sahiba and we'll review that and potentially follow up with you if you like. In terms of the chapters that we see, so the first one is govern and secure AI. There's actually a webinar tomorrow on governing and securing AI with us and the Guardian team if you or your clients would like to attend. And the next chapter is gets into governing agentic AI. So this is something that Neil touched on. We're going to start announcing that at Gardner Data Analytics in March and then continue to build on it throughout the year. The other thing you'll notice is the Credo compliance accelerators that Ian talked about. So that will be launched on March 25th with some marketing content there that will continue to build with a major market moment around that in May. And then when we get to think there's a really exciting trism AI security solution that's coming that we're still working on the the final details of how it's going to show up but that's probably going to be a big focus for us as well as agentic AI. And then chapter four again continuing to scale agentic AI building those capabilities in terms of both evaluation metrics and other ways of governing agents. And again if you have any questions, feedback, anything, please let me know. Feel free to reach out through the form or directly. And then the other thing just a reminder to keep sharing those client references. We love the client zero story that Michelle talked about as well as the one that Mohammed mentioned with Ian. So if you have a client that you think would be a good Watson X governance story, please feel free to let us know. Thank you and pass back to you Marta. Thank you so much. So thank you for all the updates. Thank you so much for sharing all the new enhancements and of course fantastic to listen to this WinStory shared by Mohammed. And thank you so much for all the participation today at the enablement call. And also thank you for all the thank you to all the speakers for sharing all the tremendous information for us. So I would encourage you to check how you can use all the content which we prepared on seismic to accelerate client conversations. Of course stay tuned for this upcoming campaign which we are going to launch with IBMC. And there is also a new playbook, fantastic asset which you can use also from our client engineering team for your pilot proposals. Please remember that is really very precious information if you code your opportunity with this product code as you can see there is also an updated proposal template just to be for you ready to use if you want to accelerate your pilot progression and propose and include technology expert lab services. And for any questions please reach out to myself or moving to the next slide there is all worldwide team ready for any question to respond if you may have considering. We want to be part of your success so thank you so much for today and happy selling.\n"
     ]
    }
   ],
   "source": [
    "#import whisper\n",
    "\n",
    "#model = whisper.load_model(\"medium\")  # You can also use 'small' or 'large'\n",
    "result = model.transcribe(\"xgov_team_call.wav\")\n",
    "\n",
    "print(result[\"text\"])  # This prints the full transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgove_team_call.txt', \"w\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = result[\"text\"].split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10605"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiocap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
